$ python server_nlp.py 
INFO flower 2022-03-01 12:59:32,706 | app.py:80 | Flower server running (insecure, 10 rounds)
INFO flower 2022-03-01 12:59:32,706 | server.py:118 | Initializing global parameters
INFO flower 2022-03-01 12:59:32,706 | server.py:304 | Requesting initial parameters from one random client
INFO flower 2022-03-01 13:00:39,717 | server.py:307 | Received initial parameters from one random client
INFO flower 2022-03-01 13:00:39,718 | server.py:120 | Evaluating initial parameters
INFO flower 2022-03-01 13:00:39,718 | server.py:133 | FL starting
DEBUG flower 2022-03-01 13:00:39,718 | server.py:255 | fit_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:04:50,673 | server.py:264 | fit_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:04:51,192 | server.py:205 | evaluate_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:06:33,742 | server.py:214 | evaluate_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:06:33,742 | server.py:255 | fit_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:10:44,713 | server.py:264 | fit_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:10:45,169 | server.py:205 | evaluate_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:12:27,571 | server.py:214 | evaluate_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:12:27,571 | server.py:255 | fit_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:16:39,039 | server.py:264 | fit_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:16:39,484 | server.py:205 | evaluate_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:18:21,892 | server.py:214 | evaluate_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:18:21,893 | server.py:255 | fit_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:22:32,223 | server.py:264 | fit_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:22:32,637 | server.py:205 | evaluate_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:24:14,960 | server.py:214 | evaluate_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:24:14,961 | server.py:255 | fit_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:28:25,606 | server.py:264 | fit_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:28:26,012 | server.py:205 | evaluate_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:30:08,455 | server.py:214 | evaluate_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:30:08,455 | server.py:255 | fit_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:34:19,667 | server.py:264 | fit_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:34:20,097 | server.py:205 | evaluate_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:36:02,470 | server.py:214 | evaluate_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:36:02,471 | server.py:255 | fit_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:40:12,913 | server.py:264 | fit_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:40:13,313 | server.py:205 | evaluate_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:41:55,681 | server.py:214 | evaluate_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:41:55,681 | server.py:255 | fit_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:46:06,838 | server.py:264 | fit_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:46:07,233 | server.py:205 | evaluate_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:47:50,105 | server.py:214 | evaluate_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:47:50,105 | server.py:255 | fit_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:52:00,515 | server.py:264 | fit_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:52:00,935 | server.py:205 | evaluate_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:53:43,421 | server.py:214 | evaluate_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:53:43,421 | server.py:255 | fit_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:57:53,759 | server.py:264 | fit_round received 2 results and 0 failures
DEBUG flower 2022-03-01 13:57:54,160 | server.py:205 | evaluate_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 13:59:36,695 | server.py:214 | evaluate_round received 2 results and 0 failures
INFO flower 2022-03-01 13:59:36,695 | server.py:172 | FL finished in 3536.9771929889976
INFO flower 2022-03-01 13:59:36,703 | app.py:119 | app_fit: losses_distributed [(1, 0.005944862030446529), (2, 0.006255514454096556), (3, 0.005841835867613554), (4, 0.006638399790972471), (5, 0.007804371416568756), (6, 0.008281353861093521), (7, 0.008450006134808064), (8, 0.008410667069256306), (9, 0.008976810611784458), (10, 0.009218862280249596)]
INFO flower 2022-03-01 13:59:36,703 | app.py:120 | app_fit: metrics_distributed {}
INFO flower 2022-03-01 13:59:36,703 | app.py:121 | app_fit: losses_centralized []
INFO flower 2022-03-01 13:59:36,703 | app.py:122 | app_fit: metrics_centralized {}
DEBUG flower 2022-03-01 13:59:36,703 | server.py:205 | evaluate_round: strategy sampled 2 clients (out of 2)
DEBUG flower 2022-03-01 14:01:19,155 | server.py:214 | evaluate_round received 2 results and 0 failures
INFO flower 2022-03-01 14:01:19,155 | app.py:132 | app_evaluate: federated loss: 0.009218862280249596
INFO flower 2022-03-01 14:01:19,155 | app.py:136 | app_evaluate: results [('ipv4:10.24.167.165:50540', EvaluateRes(loss=0.009218862280249596, num_examples=782, accuracy=0.0, metrics={'accuracy': 0.93})), ('ipv4:10.24.167.162:52576', EvaluateRes(loss=0.009218862280249596, num_examples=782, accuracy=0.0, metrics={'accuracy': 0.93}))]
INFO flower 2022-03-01 14:01:19,155 | app.py:138 | app_evaluate: failures []


*********************************

$ python client_nlp.py --idx 1 --ip 10.24.167.253:8080
ip 10.24.167.253:8080
idx 1
lr 0.1
Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias']
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/i-xxx/miniconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Reusing dataset imdb (/home/i-xxx/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1006.23it/s]
Loading cached shuffled indices for dataset at /home/i-xxx/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-8a9e43a6ac4acdff.arrow
Loading cached shuffled indices for dataset at /home/i-xxx/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-2eff9f118d84c6fe.arrow
Loading cached shuffled indices for dataset at /home/i-xxx/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-c0cc2c21e6f9b20f.arrow
==> Training on a subset  1
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:04<00:00,  3.18ba/s]
Loading cached processed dataset at /home/i-xxx/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f1a1ce33b5b5fb95.arrow
DEBUG flower 2022-03-01 13:00:38,640 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2022-03-01 13:00:38,640 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2022-03-01 13:00:38,640 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2022-03-01 13:00:38,641 | connection.py:36 | ChannelConnectivity.READY
 [=========================== 391/391 ============================>]  Step: 241ms | Tot: 2m26s | Loss: 0.296 | Acc: 87.752% (10969/12500)   
 [=========================== 782/782 ============================>]  Step: 34ms | Tot: 1m40s | Loss: 0.205 | Acc: 91.872% (22968/25000)    
Saving... accuracy 91.872
 [=========================== 391/391 ============================>]  Step: 241ms | Tot: 2m26s | Loss: 0.190 | Acc: 93.080% (11635/12500)   
 [=========================== 782/782 ============================>]  Step: 34ms | Tot: 1m40s | Loss: 0.205 | Acc: 92.368% (23092/25000)    
Saving... accuracy 92.368
 [=========================== 391/391 ============================>]  Step: 241ms | Tot: 2m26s | Loss: 0.127 | Acc: 95.528% (11941/12500)   
 [=========================== 782/782 ============================>]  Step: 34ms | Tot: 1m40s | Loss: 0.206 | Acc: 92.312% (23078/25000)    
 [=========================== 391/391 ============================>]  Step: 242ms | Tot: 2m26s | Loss: 0.083 | Acc: 97.128% (12141/12500)   
 [=========================== 782/782 ============================>]  Step: 34ms | Tot: 1m40s | Loss: 0.267 | Acc: 90.708% (22677/25000)    
 [=========================== 391/391 ============================>]  Step: 240ms | Tot: 2m26s | Loss: 0.055 | Acc: 98.336% (12292/12500)   
 [=========================== 782/782 ============================>]  Step: 34ms | Tot: 1m40s | Loss: 0.256 | Acc: 91.952% (22988/25000)    
 [=========================== 391/391 ============================>]  Step: 241ms | Tot: 2m26s | Loss: 0.034 | Acc: 98.976% (12372/12500)   
 [=========================== 782/782 ============================>]  Step: 34ms | Tot: 1m40s | Loss: 0.320 | Acc: 91.524% (22881/25000)    
 [=========================== 391/391 ============================>]  Step: 241ms | Tot: 2m26s | Loss: 0.028 | Acc: 99.216% (12402/12500)   
 [=========================== 782/782 ============================>]  Step: 34ms | Tot: 1m40s | Loss: 0.298 | Acc: 92.220% (23055/25000)    
 [=========================== 391/391 ============================>]  Step: 241ms | Tot: 2m26s | Loss: 0.029 | Acc: 99.008% (12376/12500)   
 [=========================== 782/782 ============================>]  Step: 34ms | Tot: 1m40s | Loss: 0.308 | Acc: 92.332% (23083/25000)    
 [============================ 391/391 ===========================>]  Step: 241ms | Tot: 2m26s | Loss: 0.019 | Acc: 99.488% (12436/12500)   
 [============================ 782/782 ===========================>]  Step: 34ms | Tot: 1m40s | Loss: 0.362 | Acc: 91.736% (22934/25000)    
 [============================ 391/391 ===========================>]  Step: 242ms | Tot: 2m26s | Loss: 0.016 | Acc: 99.544% (12443/12500)   
 [============================ 782/782 ===========================>]  Step: 34ms | Tot: 1m40s | Loss: 0.325 | Acc: 91.980% (22995/25000)    
DEBUG flower 2022-03-01 14:01:19,180 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2022-03-01 14:01:19,180 | app.py:72 | Disconnect and shut down
==> best accuracy: 92.368


*************************************

$ python client_nlp.py --idx 0 --ip 10.24.167.253:8080 
ip 10.24.167.253:8080
idx 0
lr 0.1
Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias']
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/i-xxx/miniconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Reusing dataset imdb (/home/i-xxx/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 994.46it/s]
Loading cached shuffled indices for dataset at /home/i-xxx/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-8a9e43a6ac4acdff.arrow
Loading cached shuffled indices for dataset at /home/i-xxx/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-2eff9f118d84c6fe.arrow
Loading cached shuffled indices for dataset at /home/i-xxx/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-c0cc2c21e6f9b20f.arrow
==> Training on a subset  0
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:04<00:00,  3.16ba/s]
Loading cached processed dataset at /home/i-xxx/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f1a1ce33b5b5fb95.arrow
DEBUG flower 2022-03-01 13:00:38,710 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2022-03-01 13:00:38,711 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2022-03-01 13:00:38,711 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2022-03-01 13:00:38,711 | app.py:61 | Opened (insecure) gRPC connection
 [=========================== 391/391 ============================>]  Step: 241ms | Tot: 2m26s | Loss: 0.289 | Acc: 88.000% (11000/12500)   
 [=========================== 782/782 ============================>]  Step: 34ms | Tot: 1m40s | Loss: 0.203 | Acc: 92.008% (23002/25000)    
Saving... accuracy 92.008
 [=========================== 391/391 ============================>]  Step: 241ms | Tot: 2m26s | Loss: 0.176 | Acc: 93.608% (11701/12500)   
 [=========================== 782/782 ============================>]  Step: 34ms | Tot: 1m40s | Loss: 0.244 | Acc: 91.064% (22766/25000)    
 [=========================== 391/391 ============================>]  Step: 241ms | Tot: 2m26s | Loss: 0.121 | Acc: 95.744% (11968/12500)   
 [=========================== 782/782 ============================>]  Step: 34ms | Tot: 1m40s | Loss: 0.200 | Acc: 92.320% (23080/25000)    
Saving... accuracy 92.32
 [=========================== 391/391 ============================>]  Step: 241ms | Tot: 2m26s | Loss: 0.078 | Acc: 97.336% (12167/12500)   
 [=========================== 782/782 ============================>]  Step: 34ms | Tot: 1m40s | Loss: 0.233 | Acc: 92.128% (23032/25000)    
 [=========================== 391/391 ============================>]  Step: 241ms | Tot: 2m26s | Loss: 0.052 | Acc: 98.344% (12293/12500)   
 [=========================== 782/782 ============================>]  Step: 34ms | Tot: 1m40s | Loss: 0.322 | Acc: 91.548% (22887/25000)    
 [=========================== 391/391 ============================>]  Step: 242ms | Tot: 2m26s | Loss: 0.040 | Acc: 98.688% (12336/12500)   
 [=========================== 782/782 ============================>]  Step: 34ms | Tot: 1m40s | Loss: 0.272 | Acc: 92.452% (23113/25000)    
Saving... accuracy 92.452
 [=========================== 391/391 ============================>]  Step: 241ms | Tot: 2m26s | Loss: 0.024 | Acc: 99.264% (12408/12500)   
 [=========================== 782/782 ============================>]  Step: 34ms | Tot: 1m40s | Loss: 0.301 | Acc: 92.272% (23068/25000)    
 [=========================== 391/391 ============================>]  Step: 241ms | Tot: 2m26s | Loss: 0.029 | Acc: 99.112% (12389/12500)   
 [=========================== 782/782 ============================>]  Step: 34ms | Tot: 1m40s | Loss: 0.257 | Acc: 92.784% (23196/25000)    
Saving... accuracy 92.784
 [============================ 391/391 ===========================>]  Step: 242ms | Tot: 2m26s | Loss: 0.020 | Acc: 99.400% (12425/12500)   
 [============================ 782/782 ===========================>]  Step: 34ms | Tot: 1m40s | Loss: 0.282 | Acc: 92.260% (23065/25000)    
 [============================ 391/391 ===========================>]  Step: 242ms | Tot: 2m26s | Loss: 0.017 | Acc: 99.376% (12422/12500)   
 [============================ 782/782 ===========================>]  Step: 34ms | Tot: 1m40s | Loss: 0.318 | Acc: 92.652% (23163/25000)    
DEBUG flower 2022-03-01 14:01:19,190 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2022-03-01 14:01:19,191 | app.py:72 | Disconnect and shut down
==> best accuracy: 92.784
